<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies | RexBlog</title>
<meta name=keywords content="MAS,Agent"><meta name=description content="多智能体系统设计"><meta name=author content="Rex"><link rel=canonical href=http://rextechie.github.io/posts/paper_note/multi_agent_design/><link crossorigin=anonymous href=/assets/css/stylesheet.56d5e73e1a36d8bc0a4f450d156a288bf54a46b72e29e3f236c46370aa489a22.css integrity="sha256-VtXnPho22LwKT0UNFWooi/VKRrcuKePyNsRjcKpImiI=" rel="preload stylesheet" as=style><link rel=icon href=http://rextechie.github.io/favicon/favicon_32x32.png><link rel=icon type=image/png sizes=16x16 href=http://rextechie.github.io/favicon/favicon_16x16.png><link rel=icon type=image/png sizes=32x32 href=http://rextechie.github.io/favicon/favicon_32x32.png><link rel=apple-touch-icon href=http://rextechie.github.io/favicon/favicon_32x32.png><link rel=mask-icon href=http://rextechie.github.io/favicon/favicon_32x32.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://rextechie.github.io/posts/paper_note/multi_agent_design/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>const config={startOnLoad:!0,theme:"default",themeVariables:{lineColor:"#fafafa",darkMode:!0},flowchart:{useMaxWidth:!1,htmlLabels:!0}};mermaid.initialize(config),window.onload=()=>{window.mermaid.init(void 0,document.querySelectorAll(".language-mermaid"))}</script><meta property="og:url" content="http://rextechie.github.io/posts/paper_note/multi_agent_design/"><meta property="og:site_name" content="RexBlog"><meta property="og:title" content="Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies"><meta property="og:description" content="多智能体系统设计"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-06-19T11:27:17+08:00"><meta property="article:modified_time" content="2025-06-19T11:27:17+08:00"><meta property="article:tag" content="MAS"><meta property="article:tag" content="Agent"><meta property="og:image" content="http://rextechie.github.io/images/profile.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://rextechie.github.io/images/profile.png"><meta name=twitter:title content="Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies"><meta name=twitter:description content="多智能体系统设计"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://rextechie.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies","item":"http://rextechie.github.io/posts/paper_note/multi_agent_design/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies","name":"Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies","description":"多智能体系统设计","keywords":["MAS","Agent"],"articleBody":"基本信息 标题: Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies 作者: Han Zhou（通讯作者）、Ruoxi Sun、Hamid Palangi、Shariq Iqbal、Ivan Vulić、Anna Korhonen和Sercan Ö. Arık。 作者单位: Google和剑桥大学 期刊/会议: ArXiv 发表年份: 2025.02.04 DOI: 2502.02533 开源地址: Github 关键词: Multi-Agent System, Large Language Models 研究问题 (Research Questions) 大语言模型，作为多个相互交互协作的智能体，可以解决复杂任务。这些智能体通过声明其功能的提示词以及协调智能体间交互的拓扑结构进行编程。本文所研究的主要问题是优化多智能体系统中的提示词以及智能体的拓扑结构。\n研究背景 (Background) 尽管最近的研究探讨了自动化智能体设计各个方面，但在理解哪些因素对改进MAS性能最为关键方面仍存在差距。例如，DSPy自动化了设计示例以改进提示编程的过程。J Li(More agents is all you need作者)提出通过扩大多数投票中的代理数量来优化MAS。ADAS通过基于LLM的元代理编程代码表达的新拓扑。AFlow在预定义操作集中使用蒙特卡洛树搜索来寻找更好的拓扑。然而，包括提示词和拓扑在内的多个设计空间之间的相互作用仍然不明确。\n核心贡献 (Key Contributions) 深入分析了影响基于LLM的MAS性能的设计因素，强调了prompt的重要性，并确定了有影响力的拓扑结构。 提出了一种名为Mass的新型多阶段优化器，通过在具有影响力的搜索空间中交错优化prompt和拓扑结构来自动化MAS设计。 大量数据在各种评估基准上显示出显著的性能提升，为构建有效的未来多智能体系统提供了指导。 设计多智能体系统（Designing Multi-Agent Systems） 作者认为MAS的设计可以分为两个层级：块级设计(Block-level)和工作流编排(Workflow-level orchestration)。对于块级，目标是设计单个智能体，通过更好的提示词设计最好的提示词来表现出特定的角色。对于工作流编排，它的优化涉及要包含智能体的类型和数量，以及如何以最有效的方式编排他们，这被称为拓扑优化。\n$\\mathcal{W}^{*}(a)=\\arg\\max\\mathbb{E}_{(x,y)\\sim\\mathcal{D}}[f(\\mathcal{W}(a)(x)),y]$\n块级：智能体的提示词设计（Block-level: Prompt Design for Agents） 对于块级，对下游任务影响最主要的是prompt，它定义了智能体的角色（例如，“You are an expert in reflecting on errors…”），提供额外的指令来塑造其行为（例如，“You should think step by step…”）以及可选地包含少量示例（zero-shot/one-shot/few-shot）来指导智能体的回复。比如，一种SOAT提示词优化器同时搜索指令和少量示例，其中示例是从模型自身在验证集上的正确预测中引导出来的，基于验证指标。基于这些示例，提示词优化器会为指令提出一些候选方案，并提供数据集摘要或各种提示词以提高候选方案的多样性。然后指令和示例会被联合优化。\n尽管大家都指导LLMs对提示词很敏感，但将自动提示词优化（APO，automatic prompt optimization）技术应用与多智能体系统并非易事。与单轮任务不同，单轮任务中APO可以通过将提示词视为可优化变量并将验证集的性能作为目标来轻松执行。在 MAS 中，由于智能体之间的相互依赖性（例如，一个智能体的输出可能是另一个智能体的输入，且中间输出的真实响应不可用）以及随着参与智能体数量n的增加而呈指数级增长的组合优化复杂性，APO变得更加复杂。当n增加时，奖励信号也变得更加稀疏，使得难以在MAS系统中使用APO；因此，MAS中的许多先前工作仍然主要使用手动设计提示词，而不是将提示词作为MAS设计中可优化的组件。\n为了系统地理解提示词设计在MAS中的影响，作者具体且定量地分析了提示词优化的效果，并将其有效性与MAS文献中常见的其他操作进行比较，例如使用更多代理进行扩展但使用默认提示。我们在CoT智能体上进行APO，结合通过MIPRO的指令优化和1-shot示例优化，并公平地将总推理token成本与self-consistency、self-refine和multi-agent debate进行比较。结果如下图所示，提示词为智能体提供了更具信息性的指令和示例，在token有效性方面显示出显著优势，优于其他构建模块。此外，通过在提示词优化智能体的基础上应用self-consistency，作者观察到token成本的扩展性能有所提高，而在扩展智能体数量的标准方法（例如SC或Reflect）中，饱和得更早。这一实证观察揭示了提示词的重要性，同时为设计有效的MAS提供了早期证据——在扩展拓扑之前先局部优化代理。\n工作流级搜索空间设计（Workflow-level Search Space Design） 在工作流层面，主要关注的是协调智能体以有效地达到最佳性能。作为MAS特有的一个相对较新的概念，拓扑优化最近引起了显著关注。然而，尽管现有研究大多强调search methods（例如发现识别最佳配置的最有效和高效的方法），但对搜索空间设计的关注较少，而搜索空间设计决定了任何搜索算法的范围和边界。这种不平衡与neural architecture search（NAS）的历史发展相似。最初，该领域集中于复杂的搜索方法，如贝叶斯优化和可微分搜索。后续的工作强调了搜索空间设计的重要性，这一方面常常被忽视，认为其同样重要，甚至更为关键。受到这一见解的启发，我们假设人为设计的拓扑可能不是最优的，而自动拓扑优化（可能被框定为一个严格的优化问题）可以通过精心设计MAS的搜索空间发挥同样关键的作用。为此，我们首先定义一个富有表现力的搜索空间，类似于之前的工作，它由以下building blocks之间的连接组成：\nAggregate：智能体可以并行进行多样化的预测，之后再通过一个聚合操作获得一个统一的预测结果。聚合块可以通过$N_a$个智能体并行操作进行参数化。例如：Majority vote和Self-consistency。 Reflect：智能体可以作为验证者，基于先前的预测提供批评和改进建议。然后将反馈输入预测器或反思者本身，以进行迭代改进。同样，Reflect可以通过定义self-reflect轮次数量的$N_r$进行参数化。例如：Self-refine和Relexion。 Debate：在辩论中的智能体可以比单代理预测得出更真实的预测，其中每个辩论智能体会收集所有其他智能体的意见并提供更新后的回应。这种拓扑结构将涉及多种智能体，而$N_d$定义了辩论的回合数。 Custom Agents：虽然前三种形式的智能体代表作为多个并行、串行和智能体混合的智能体拓扑结构的大多数，但更通用的智能体定义可以插入到MAS设计空间中。例如，对于特定任务的使用案例，作者引入一个智能体作为总结，以改善在可定制设计空间中的长上下文能力。 Tool-use：构建有效的MAS，使智能体能够利用工具访问外部信息对于系统性能至关重要，例如使用检索器进行RAG和具有测试用例的执行器进行编码。作者引入工具使用作为一个可优化的二元“插入”决策$N_T \\in \\{0, 1\\}$。 为了理解各个拓扑的影响，作者在下图中报告了各种拓扑的性能。值得注意的是，并非所有拓扑都对MAS设计有利，而是只有一小部分拓扑对其有积极影响。例如，在HotpotQA中，只有Debate带来了3%的提升，而其他拓扑未能改善甚至降低系统性能。我们在LiveCodeBench的测试输出预测子任务中再次观察到类似趋势。这强调了在搜索空间的影响集合中进行搜索的重要性，而包含递减的构建块不仅可能导致更高的搜索复杂性，还可能降低性能。\nMASS: Multi-Agent System Search 前面作者分析，定义搜索空间非常的重要，在这个基础上提出了一种多阶段优化算法，即多智能体系统搜索（MASS，Multi-Agent System Search）。这超越了之前只关注优化工作流拓扑而没有合适的提示词设计的研究。相反，作者的方法展示了通过适当优化提示词和精心设计的搜索空间进行MAS设计的更有效。MASS算法如下图所示，遵循从局部到全局、从块级到工作流的，通过以下详细的每阶段优化来克服组合优化的复杂性。\n1）Block-level prompt optimization: 在组合智能体之前，首先确保单个智能体在块级别上经过彻底优化，这一步确保每个智能体在最易管理的计算预算中以最有效的指令为其角色做好准备。为了进一步克服在大型MAS空间上联合优化的复杂性，我们首先通过单智能体APO来热身初始predictor，$a_{0}^{*} \\leftarrow O_{\\mathcal{D}}(a_{0})$，其中指令和示例都与模块化提示词优化器O共同优化。接着在预热过predictor后的条件下，继续以最少数量的智能体优化每个拓扑，$a_{i}^{*} \\leftarrow O_{\\mathcal{D}}(a_{i} \\mid a_{0}^{*})$，这样，2个predictor与1个debator配对形成最小构建块作为debate拓扑，从而降低优化的复杂性，并且该拓扑可以在以后通过更多的predictor和debator进行扩展，但都配备了优化的提示。为了衡量每个构建块的影响，我们在优化完成后存储验证性能。重要的是，尽管阶段（1）作为每个构建块的热身阶段，但它仍然是一个关键阶段，确保后续的拓扑优化在一个有效的空间中进行，组合表现良好的代理，而不是因任何手动提示的格式不佳的代理的复合影响而受苦。\n2）Workflow topology optimization：在此阶段，专注于优化整体MAS结构，确定智能体之间最有效的排列和连接。之前的分析显示，有利的拓扑仅占整个设计空间的一小部分。因此，重点旨在将表现强劲的拓扑的精髓提炼到一个精简的空间，从而使工作流级别的拓扑搜索更加高效。在此，提出测量增量影响$I_{a_{i}} = \\frac{\\mathcal{E}(a_{i}^{*})}{\\mathcal{E}(a_{0}^{*})}$，量化将拓扑$a_{i}$整合到初始代理$a_{0}$中的相对增益。根据直觉，影响力大的维度具有更高的选择概率，如果$u \u003e p_{a}$，则激活相应的拓扑维度a，其中$u ∼ U(0, 1)$且$p_{a} = Softmax(I_{a}, t)$。为了将多样的拓扑组合成一个统一的空间，我们通过基于规则的顺序约束工作流以减少优化复杂性，遵循预定义的顺序，如[summarize，reflect，debate，aggregate]。在预定义的设计空间上整合拒绝采样，拒绝任何停用的维度或超过代理数量最大预算B的无效拓扑组合。\n3）Workflow-level prompt optimization：作为最后一步，我们将整个MAS设计视为一个整体实体，并在第二阶段发现的最佳拓扑$\\mathcal{W}^{*} = \\mathcal{O}_{\\mathcal{D}}(\\mathcal{W}_{c}^{*})$的条件下进行额外一轮的提示优化。值得注意的是，尽管在第一阶段提示是在个体层面进行优化的，这一阶段起到了适应或微调的作用，确保提示适合在MAS中进行编排，并且优化了代理之间的相互依赖性。实验表明，这一阶段通常会带来实际的好处。\n试验（Experiments） 基准（Benchmarks） 推理：Hendryck’s MATH、DROP 多跳长文本：HotpotQA、MuSiQue、2WikiMultiHopQA 编程：MBBPP、HumanEval、LCB(LiveCodeBench) 基线（Baselines） CoT：通过零样本提示进行直接思维链推理。 CoT-SC：具有自一致性，从多样化的推理轨迹中找到最一致的答案。 Self-Refine：反思性智能体验证和自我改进预测。 Multi-Agent Debate：智能体通过辩论答案并聚合其他智能体的信息。 ADAS：一种自动智能体设计框架，基于LLM的元智能体根据先前的评估迭代提出新智能体 AFlow：通过蒙特卡罗树搜索在一组预定义的操作符上进行自动工作流设计。 作者通过将代理的最大数量限制为10来公平比较所有基线。\n实验设置（Setup） MASS整合了最先进的提示词优化器MIPRO，通过贝叶斯替代模型（Bayesian surrogate model）优化每个指令和示例。作者限制示例数量为3，候选指令数量为10，每个智能体迭代优化10次。在所有任务的拓扑优化中，作者通过拒绝采样（Rejection sampling）算法搜索10中不同的拓扑结构。与拓扑优化同时，每个拓扑在验证集上评估3次以稳定预测。优化后的MAS随后在保留的测试集上进行了三次运行并报告结果。对于模型，Temperature = 0.7, 最大输出token为4096，Softmax中的t设置为0.05以增强每个搜索维度的选择概率$p_{a}$。在所有阶段，作者都在评估器和优化器中实现了相同的LLM骨干模型。\n主要结果（Main Results） 如结果所示，MASS在多智能体系统中取得了显著的提升。通过将MASS与最先进的自动智能体设计基线ADAS和AFlow进行比较，作者注意到，即使ADAS已经基于常见的智能体形式来生成元智能体，它也仅带来了细微的提升。元智能体不断提出复杂的拓扑结构，但没有优化提示词设计。另一方面，AFlow在2WikiMQA和HumanEval上表现出与Mass相当的竞争力。\n作者将AFlow的性能归因于：1）其“扩展”阶段基于错误日志生成新节点，该日志将预测与真实情况进行对比，从而提供隐式文本梯度，以反映提示设计中的任何格式错误；2）在预定义的操作符集合中进行更精细的搜索空间。尽管AFlow在搜索空间设计的重要性上与MASS有相似的灵感，但它仍然缺乏提示词优化阶段来正确优化其预定义的操作符，导致在MATH和MuSiQue的MAS搜索结果中表现不佳。与这些基线不同，Mass带来的持续改进突显了在提示和拓扑设计空间中进行搜索的重要性。\n消融优化阶段（Ablating optimization stages） 首先，注意到块级优化和单智能体优化之间有很大的增益，平均为6%，这表明MAS通过在构建块内优化其智能体受益匪浅。此外，从阶段(1)到(2)，通过在搜索最佳配置时组合有影响力的拓扑结构，可以实现额外的3%增益。在此，作者提供了一个额外的消融研究，探讨在没有事先进行提示优化或没有搜索空间修剪的情况下进行阶段(2)。图（右）显示，这两者对于有效的搜索空间探索都是至关重要的。最后，MASS通过在最佳找到的拓扑上进行工作流级提示优化获得了进一步的增益（约2%），这表明优化提示以建模智能体之间的相互依赖性在MAS设计中是有益的。\nMASS的成本效益（Cost-effectiveness of MASS） 作者对MASS的成本效益进行了分析。特别是，作者可视化了MASS的优化轨迹，如图所示。MASS的轨迹显示出一种稳定的优化趋势，通过交替搜索更好的提示词和拓扑结构，逐步提高验证性能。然而，对于没有明确提示词优化阶段的自动设计基线，由于MCTS的性质，AFlow在其优化中暴露出更大的方差，而ADAS则陷入发现过于复杂的拓扑结构，这些结构似乎不如提示词计设空间有效。总体而言，MASS的优化轨迹突出了在有效设计空间中进行优化的重要性，其中交替优化通过更多连续的奖励进一步解决了复杂性。\n最佳MAS架构与原则（Best-found MAS architectures \u0026 Design principles） 作者进一步检查了一个优化提示词的示例以及MASS在发现更有效拓扑结构中的轨迹，如图所示。优化从zero-shot CoT智能体开始，很快MASS在阶段(1)中通过其优化提示词识别出高性能拓扑。然而，如阶段(2)中所发现的，聚合更多并行智能体实际上比多智能体辩论更有优势。工作流级别的提示词优化随后导致了聚合的最佳预测器。整体优化流程为我们构建有效MAS的指南提供了启示：1）在将个体智能体组合成MAS之前，适当优化个体智能体是重要的；2）通过组合有影响力的拓扑可以构建更有效的MAS；3）建模智能体之间的相互依赖是有益的，可以通过工作流级别的联合优化实现。\n我的思考 (Personal Thoughts) 本文对于智能体的优化，着重关注提示词的优化，这一下就抓到了LLM的核心。而对于工作流编排部分，着重需要优化的是工作流的拓扑结构。这给后续多智能体的开发提供了指导，可以增加一些对于智能体提示词和工作流拓扑结构的优化模块。\n参考文献 (References) Forms of LLM-based agentic systems S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. R. Narasimhan, and Y. Cao. React: Synergizing reasoning and acting in language models. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=WE_vluYUL-X. Q. Wu, G. Bansal, J. Zhang, Y. Wu, S. Zhang, E. Zhu, B. Li, L. Jiang, X. Zhang, and C. Wang. Autogen: Enabling next-gen llm applications via multi-agent conversation framework. arXiv preprint arXiv:2308.08155, 2023. W. Chen, Y. Su, J. Zuo, C. Yang, C. Yuan, C.-M. Chan, H. Yu, Y. Lu, Y.-H. Hung, C. Qian, Y. Qin, X. Cong, R. Xie, Z. Liu, M. Sun, and J. Zhou. Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors. In The Twelfth International Conference on Learning Representations, 2024b. URL https://openreview.net/forum?id=EHg5GDnyq1. J. Li, Q. Zhang, Y. Yu, Q. FU, and D. Ye. More agents is all you need. Transactions on Machine Learning Research, 2024a. ISSN 2835-8856. URL https://openreview.net/forum?id=bgzUSZ8aeg. X. Wang, J. Wei, D. Schuurmans, Q. V. Le, E. H. Chi, S. Narang, A. Chowdhery, and D. Zhou. Selfconsistency improves chain of thought reasoning in language models. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id= 1PL1NIMMrw. A. Madaan, N. Tandon, P. Gupta, S. Hallinan, L. Gao, S. Wiegreffe, U. Alon, N. Dziri, S. Prabhumoye, Y. Yang, et al. Self-refine: Iterative refinement with self-feedback. Advances in Neural Information Processing Systems, 36, 2024. A. Singh, A. Ehtesham, S. Kumar, and T. T. Khoei. Agentic retrieval-augmented generation: A survey on agentic rag. arXiv preprint arXiv:2501.09136, 2025. X. Chen, M. Lin, N. Schärli, and D. Zhou. Teaching large language models to self-debug. In The Twelfth International Conference on Learning Representations, 2024d. URL https://openreview. net/forum?id=KuPixIqPiq. L. Lin, J. Fu, P. Liu, Q. Li, Y. Gong, J. Wan, F. Zhang, Z. Wang, D. Zhang, and K. Gai. Just ask one more time! self-agreement improves reasoning of language models in (almost) all scenarios. In L.-W. Ku, A. Martins, and V. Srikumar, editors, Findings of the Association for Computational Linguistics: ACL 2024, pages 3829–3852, Bangkok, Thailand, Aug. 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.230. URL https://aclanthology.org/2024. findings-acl.230/. J. Chen, S. Saha, and M. Bansal. ReConcile: Round-table conference improves reasoning via consensus among diverse LLMs. In L.-W. Ku, A. Martins, and V. Srikumar, editors, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 7066–7085, Bangkok, Thailand, Aug. 2024a. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.381. URL https://aclanthology.org/2024.acl-long.381/. Q. Wang, Z. Wang, Y. Su, H. Tong, and Y. Song. Rethinking the bounds of LLM reasoning: Are multi-agent discussions the key? In L.-W. Ku, A. Martins, and V. Srikumar, editors, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6106–6131, Bangkok, Thailand, Aug. 2024c. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.331. URL https://aclanthology.org/2024.acl-long.331/. J. Zhang, X. Xu, N. Zhang, R. Liu, B. Hooi, and S. Deng. Exploring collaboration mechanisms for LLM agents: A social psychology view. In L.-W. Ku, A. Martins, and V. Srikumar, editors, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14544–14607, Bangkok, Thailand, Aug. 2024c. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.782. URL https://aclanthology.org/2024.acl-long.782/. Y. Du, S. Li, A. Torralba, J. B. Tenenbaum, and I. Mordatch. Improving factuality and reasoning in language models through multiagent debate. In Forty-first International Conference on Machine Learning, ICML 2024, Vienna, Austria, July 21-27, 2024. OpenReview.net, 2024. URL https: //openreview.net/forum?id=zj7YuTE4t8. A. Khan, J. Hughes, D. Valentine, L. Ruis, K. Sachan, A. Radhakrishnan, E. Grefenstette, S. R. Bowman, T. Rocktäschel, and E. Perez. Debating with more persuasive LLMs leads to more truthful answers. In Forty-first International Conference on Machine Learning, 2024. URL https://openreview. net/forum?id=iLCZtl7FTa. C. Qian, Z. Xie, Y. Wang, W. Liu, Y. Dang, Z. Du, W. Chen, C. Yang, Z. Liu, and M. Sun. Scaling large-language-model-based multi-agent collaboration. arXiv preprint arXiv:2406.07155, 2024. J. Wang, J. Wang, B. Athiwaratkun, C. Zhang, and J. Zou. Mixture-of-agents enhances large language model capabilities. arXiv preprint arXiv:2406.04692, 2024b. Automatic optimization for MAS S. Zhang, J. Zhang, J. Liu, L. Song, C. Wang, R. Krishna, and Q. Wu. Offline training of language model agents with functions as learnable weights. In Forty-first International Conference on Machine Learning, 2024d. URL https://openreview.net/forum?id=2xbkWiEuR1. W. Zhang, K. Tang, H. Wu, M. Wang, Y. Shen, G. Hou, Z. Tan, P. Li, Y. Zhuang, and W. Lu. Agentpro: Learning to evolve via policy-level reflection and optimization. In L.-W. Ku, A. Martins, and V. Srikumar, editors, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5348–5375, Bangkok, Thailand, Aug. 2024e. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.292. URL https://aclanthology.org/2024.acl-long.292/. S. Qiao, N. Zhang, R. Fang, Y. Luo, W. Zhou, Y. Jiang, C. Lv, and H. Chen. AutoAct: Automatic agent learning from scratch for QA via self-planning. In L.-W. Ku, A. Martins, and V. Srikumar, editors, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3003–3021, Bangkok, Thailand, Aug. 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.165. URL https://aclanthology.org/2024. acl-long.165/. O. Khattab, A. Singhvi, P. Maheshwari, Z. Zhang, K. Santhanam, S. V. A, S. Haq, A. Sharma, T. T. Joshi, H. Moazam, H. Miller, M. Zaharia, and C. Potts. DSPy: Compiling declarative language model calls into state-of-the-art pipelines. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id=sY5N0zY5Od. W. Zhou, Y. Ou, S. Ding, L. Li, J. Wu, T. Wang, J. Chen, S. Wang, X. Xu, N. Zhang, et al. Symbolic learning enables self-evolving agents. arXiv preprint arXiv:2406.18532, 2024d. Z. Li, S. Xu, K. Mei, W. Hua, B. Rama, O. Raheja, H. Wang, H. Zhu, and Y. Zhang. Autoflow: Automated workflow generation for large language model agents. arXiv preprint arXiv:2407.12821, 2024c. Y. Shang, Y. Li, K. Zhao, L. Ma, J. Liu, F. Xu, and Y. Li. Agentsquare: Automatic llm agent search in modular design space. arXiv preprint arXiv:2410.06153, 2024. Z. Liu, Y. Zhang, P. Li, Y. Liu, and D. Yang. A dynamic LLM-powered agent network for taskoriented agent collaboration. In First Conference on Language Modeling, 2024b. URL https: //openreview.net/forum?id=XII0Wp1XA9. J. Saad-Falcon, A. G. Lafuente, S. Natarajan, N. Maru, H. Todorov, E. Guha, E. K. Buchanan, M. Chen, N. Guha, C. Ré, et al. Archon: An architecture search framework for inference-time techniques. arXiv preprint arXiv:2409.15254, 2024. M. Zhuge, W. Wang, L. Kirsch, F. Faccio, D. Khizbullin, and J. Schmidhuber. GPTSwarm: Language agents as optimizable graphs. In Forty-first International Conference on Machine Learning, 2024. URL https://openreview.net/forum?id=uTC9AFXIhg. S. Hu, C. Lu, and J. Clune. Automated design of agentic systems. arXiv preprint arXiv:2408.08435, 2024a. J. Zhang, J. Xiang, Z. Yu, F. Teng, X. Chen, J. Chen, M. Zhuge, X. Cheng, S. Hong, J. Wang, et al. Aflow: Automating agentic workflow generation. arXiv preprint arXiv:2410.10762, 2024b. ","wordCount":"1308","inLanguage":"en","image":"http://rextechie.github.io/images/profile.png","datePublished":"2025-06-19T11:27:17+08:00","dateModified":"2025-06-19T11:27:17+08:00","author":{"@type":"Person","name":"Rex"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://rextechie.github.io/posts/paper_note/multi_agent_design/"},"publisher":{"@type":"Organization","name":"RexBlog","logo":{"@type":"ImageObject","url":"http://rextechie.github.io/favicon/favicon_32x32.png"}}}</script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.css><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.js crossorigin=anonymous></script><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/contrib/auto-render.min.js crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})'></script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://rextechie.github.io/ accesskey=h title="🏘️Home (Alt + H)"><img src=http://rextechie.github.io/favicon/favicon_32x32.png alt aria-label=logo height=35>🏘️Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://rextechie.github.io/posts/ title="📚 Posts"><span>📚 Posts</span></a></li><li><a href=http://rextechie.github.io/archives/ title="📅 Archives"><span>📅 Archives</span></a></li><li><a href=http://rextechie.github.io/search/ title="🔍 Search (Alt + /)" accesskey=/><span>🔍 Search</span></a></li><li><a href=http://rextechie.github.io/categories/ title="📂 Categories"><span>📂 Categories</span></a></li><li><a href=http://rextechie.github.io/tags/ title="🏷️ Tags"><span>🏷️ Tags</span></a></li><li><a href=http://rextechie.github.io/about/ title="📝 About"><span>📝 About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://rextechie.github.io/>Home</a>&nbsp;»&nbsp;<a href=http://rextechie.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies</h1><div class=post-description>多智能体系统设计</div><div class=post-meta><span title='2025-06-19 11:27:17 +0800 +0800'>June 19, 2025</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1308 words&nbsp;·&nbsp;Rex&nbsp;|&nbsp;<a href=https://github.com/RexTechie/RexTechie.github.io/blob/main/content/posts/paper_note/multi_agent_design.md rel="noopener noreferrer" target=_blank>修改</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#基本信息>基本信息</a></li><li><a href=#研究问题-research-questions>研究问题 (Research Questions)</a></li><li><a href=#研究背景-background>研究背景 (Background)</a></li><li><a href=#核心贡献-key-contributions>核心贡献 (Key Contributions)</a></li><li><a href=#设计多智能体系统designing-multi-agent-systems>设计多智能体系统（Designing Multi-Agent Systems）</a><ul><li><a href=#块级智能体的提示词设计block-level-prompt-design-for-agents>块级：智能体的提示词设计（Block-level: Prompt Design for Agents）</a></li><li><a href=#工作流级搜索空间设计workflow-level-search-space-design>工作流级搜索空间设计（Workflow-level Search Space Design）</a></li></ul></li><li><a href=#mass-multi-agent-system-search>MASS: Multi-Agent System Search</a></li><li><a href=#试验experiments>试验（Experiments）</a><ul><li><a href=#基准benchmarks>基准（Benchmarks）</a></li><li><a href=#基线baselines>基线（Baselines）</a></li><li><a href=#实验设置setup>实验设置（Setup）</a></li><li><a href=#主要结果main-results>主要结果（Main Results）</a></li><li><a href=#消融优化阶段ablating-optimization-stages>消融优化阶段（Ablating optimization stages）</a></li><li><a href=#mass的成本效益cost-effectiveness-of-mass>MASS的成本效益（Cost-effectiveness of MASS）</a></li><li><a href=#最佳mas架构与原则best-found-mas-architectures--design-principles>最佳MAS架构与原则（Best-found MAS architectures & Design principles）</a></li></ul></li><li><a href=#我的思考-personal-thoughts>我的思考 (Personal Thoughts)</a></li><li><a href=#参考文献-references>参考文献 (References)</a><ul><li><a href=#forms-of-llm-based-agentic-systems>Forms of LLM-based agentic systems</a></li><li><a href=#automatic-optimization-for-mas>Automatic optimization for MAS</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=基本信息>基本信息<a hidden class=anchor aria-hidden=true href=#基本信息>#</a></h2><ul><li><strong>标题</strong>: Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies</li><li><strong>作者</strong>: Han Zhou（通讯作者）、Ruoxi Sun、Hamid Palangi、Shariq Iqbal、Ivan Vulić、Anna Korhonen和Sercan Ö. Arık。</li><li><strong>作者单位</strong>: Google和剑桥大学</li><li><strong>期刊/会议</strong>: ArXiv</li><li><strong>发表年份</strong>: 2025.02.04</li><li><strong>DOI</strong>: <a href=https://arxiv.org/abs/2502.02533>2502.02533</a></li><li><strong>开源地址</strong>: <a href=https://github.com/facebookresearch/DocAgent>Github</a></li><li><strong>关键词</strong>: Multi-Agent System, Large Language Models</li></ul><h2 id=研究问题-research-questions>研究问题 (Research Questions)<a hidden class=anchor aria-hidden=true href=#研究问题-research-questions>#</a></h2><p>大语言模型，作为多个相互交互协作的智能体，可以解决复杂任务。这些智能体通过声明其功能的提示词以及协调智能体间交互的拓扑结构进行编程。本文所研究的主要问题是优化多智能体系统中的提示词以及智能体的拓扑结构。</p><hr><h2 id=研究背景-background>研究背景 (Background)<a hidden class=anchor aria-hidden=true href=#研究背景-background>#</a></h2><p>尽管最近的研究探讨了自动化智能体设计各个方面，但在理解哪些因素对改进MAS性能最为关键方面仍存在差距。例如，DSPy自动化了设计示例以改进提示编程的过程。J Li(More agents is all you need作者)提出通过扩大多数投票中的代理数量来优化MAS。ADAS通过基于LLM的元代理编程代码表达的新拓扑。AFlow在预定义操作集中使用蒙特卡洛树搜索来寻找更好的拓扑。然而，包括提示词和拓扑在内的多个设计空间之间的相互作用仍然不明确。</p><hr><h2 id=核心贡献-key-contributions>核心贡献 (Key Contributions)<a hidden class=anchor aria-hidden=true href=#核心贡献-key-contributions>#</a></h2><ul><li>深入分析了影响基于LLM的MAS性能的设计因素，强调了prompt的重要性，并确定了有影响力的拓扑结构。</li><li>提出了一种名为Mass的新型多阶段优化器，通过在具有影响力的搜索空间中交错优化prompt和拓扑结构来自动化MAS设计。</li><li>大量数据在各种评估基准上显示出显著的性能提升，为构建有效的未来多智能体系统提供了指导。</li></ul><hr><h2 id=设计多智能体系统designing-multi-agent-systems>设计多智能体系统（Designing Multi-Agent Systems）<a hidden class=anchor aria-hidden=true href=#设计多智能体系统designing-multi-agent-systems>#</a></h2><p>作者认为MAS的设计可以分为两个层级：块级设计(<code>Block-level</code>)和工作流编排(<code>Workflow-level orchestration</code>)。对于块级，目标是设计单个智能体，通过更好的提示词设计最好的提示词来表现出特定的角色。对于工作流编排，它的优化涉及要包含智能体的类型和数量，以及如何以最有效的方式编排他们，这被称为拓扑优化。</p><p>$\mathcal{W}^{*}(a)=\arg\max\mathbb{E}_{(x,y)\sim\mathcal{D}}[f(\mathcal{W}(a)(x)),y]$</p><h3 id=块级智能体的提示词设计block-level-prompt-design-for-agents>块级：智能体的提示词设计（Block-level: Prompt Design for Agents）<a hidden class=anchor aria-hidden=true href=#块级智能体的提示词设计block-level-prompt-design-for-agents>#</a></h3><p>对于块级，对下游任务影响最主要的是<code>prompt</code>，它定义了智能体的角色（例如，“You are an expert in reflecting on errors&mldr;”），提供额外的指令来塑造其行为（例如，“You should think step by step&mldr;”）以及可选地包含少量示例（zero-shot/one-shot/few-shot）来指导智能体的回复。比如，一种SOAT提示词优化器同时搜索指令和少量示例，其中示例是从模型自身在验证集上的正确预测中引导出来的，基于验证指标。基于这些示例，提示词优化器会为指令提出一些候选方案，并提供数据集摘要或各种提示词以提高候选方案的多样性。然后指令和示例会被联合优化。</p><p>尽管大家都指导LLMs对提示词很敏感，但将自动提示词优化（<code>APO</code>，automatic prompt optimization）技术应用与多智能体系统并非易事。与单轮任务不同，单轮任务中APO可以通过将提示词视为可优化变量并将验证集的性能作为目标来轻松执行。在 MAS 中，由于智能体之间的相互依赖性（例如，一个智能体的输出可能是另一个智能体的输入，且中间输出的真实响应不可用）以及随着参与智能体数量n的增加而呈指数级增长的组合优化复杂性，APO变得更加复杂。当n增加时，奖励信号也变得更加稀疏，使得难以在MAS系统中使用APO；因此，MAS中的许多先前工作仍然主要使用手动设计提示词，而不是将提示词作为MAS设计中可优化的组件。</p><p>为了系统地理解提示词设计在MAS中的影响，作者具体且定量地分析了提示词优化的效果，并将其有效性与MAS文献中常见的其他操作进行比较，例如使用更多代理进行扩展但使用默认提示。我们在CoT智能体上进行APO，结合通过MIPRO的指令优化和1-shot示例优化，并公平地将总推理token成本与self-consistency、self-refine和multi-agent debate进行比较。结果如下图所示，提示词为智能体提供了更具信息性的指令和示例，在token有效性方面显示出显著优势，优于其他构建模块。此外，通过在提示词优化智能体的基础上应用self-consistency，作者观察到token成本的扩展性能有所提高，而在扩展智能体数量的标准方法（例如SC或Reflect）中，饱和得更早。这一实证观察揭示了提示词的重要性，同时为设计有效的MAS提供了早期证据——在扩展拓扑之前先局部优化代理。</p><p><img alt="Accuracy vs total token counts for prompt-optimized agent" loading=lazy src=/images/20250626105724.png></p><h3 id=工作流级搜索空间设计workflow-level-search-space-design>工作流级搜索空间设计（Workflow-level Search Space Design）<a hidden class=anchor aria-hidden=true href=#工作流级搜索空间设计workflow-level-search-space-design>#</a></h3><p>在工作流层面，主要关注的是协调智能体以有效地达到最佳性能。作为MAS特有的一个相对较新的概念，<code>拓扑优化</code>最近引起了显著关注。然而，尽管现有研究大多强调<code>search methods</code>（例如发现识别最佳配置的最有效和高效的方法），但对搜索空间设计的关注较少，而搜索空间设计决定了任何搜索算法的范围和边界。这种不平衡与<code>neural architecture search（NAS）</code>的历史发展相似。最初，该领域集中于复杂的搜索方法，如贝叶斯优化和可微分搜索。后续的工作强调了搜索空间设计的重要性，这一方面常常被忽视，认为其同样重要，甚至更为关键。受到这一见解的启发，我们假设人为设计的拓扑可能不是最优的，而自动拓扑优化（可能被框定为一个严格的优化问题）可以通过精心设计MAS的搜索空间发挥同样关键的作用。为此，我们首先定义一个富有表现力的搜索空间，类似于之前的工作，它由以下<code>building blocks</code>之间的连接组成：</p><ul><li><code>Aggregate</code>：智能体可以并行进行多样化的预测，之后再通过一个聚合操作获得一个统一的预测结果。聚合块可以通过$N_a$个智能体并行操作进行参数化。例如：Majority vote和Self-consistency。</li><li><code>Reflect</code>：智能体可以作为验证者，基于先前的预测提供批评和改进建议。然后将反馈输入预测器或反思者本身，以进行迭代改进。同样，<code>Reflect</code>可以通过定义<code>self-reflect</code>轮次数量的$N_r$进行参数化。例如：Self-refine和Relexion。</li><li><code>Debate</code>：在辩论中的智能体可以比单代理预测得出更真实的预测，其中每个辩论智能体会收集所有其他智能体的意见并提供更新后的回应。这种拓扑结构将涉及多种智能体，而$N_d$定义了辩论的回合数。</li><li><code>Custom Agents</code>：虽然前三种形式的智能体代表作为多个并行、串行和智能体混合的智能体拓扑结构的大多数，但更通用的智能体定义可以插入到MAS设计空间中。例如，对于特定任务的使用案例，作者引入一个智能体作为总结，以改善在可定制设计空间中的长上下文能力。</li><li><code>Tool-use</code>：构建有效的MAS，使智能体能够利用工具访问外部信息对于系统性能至关重要，例如使用检索器进行RAG和具有测试用例的执行器进行编码。作者引入工具使用作为一个可优化的二元“插入”决策$N_T \in \{0, 1\}$。</li></ul><p>为了理解各个拓扑的影响，作者在下图中报告了各种拓扑的性能。值得注意的是，并非所有拓扑都对MAS设计有利，而是只有一小部分拓扑对其有积极影响。例如，在HotpotQA中，只有<code>Debate</code>带来了3%的提升，而其他拓扑未能改善甚至降低系统性能。我们在LiveCodeBench的测试输出预测子任务中再次观察到类似趋势。这强调了在搜索空间的影响集合中进行搜索的重要性，而包含递减的构建块不仅可能导致更高的搜索复杂性，还可能降低性能。</p><p><img alt="The performance of different topologies" loading=lazy src=/images/20250626142930.png></p><h2 id=mass-multi-agent-system-search>MASS: Multi-Agent System Search<a hidden class=anchor aria-hidden=true href=#mass-multi-agent-system-search>#</a></h2><p>前面作者分析，定义搜索空间非常的重要，在这个基础上提出了一种多阶段优化算法，即多智能体系统搜索（MASS，Multi-Agent System Search）。这超越了之前只关注优化工作流拓扑而没有合适的提示词设计的研究。相反，作者的方法展示了通过适当优化提示词和精心设计的搜索空间进行MAS设计的更有效。MASS算法如下图所示，遵循从局部到全局、从块级到工作流的，通过以下详细的每阶段优化来克服组合优化的复杂性。</p><p><img alt="Mass framework" loading=lazy src=/images/20250626152213.png></p><p><img alt="Algorithm MASS: Multi-Agent System Search" loading=lazy src=/images/20250626153418.png></p><p>1）Block-level prompt optimization: 在组合智能体之前，首先确保单个智能体在块级别上经过彻底优化，这一步确保每个智能体在最易管理的计算预算中以最有效的指令为其角色做好准备。为了进一步克服在大型MAS空间上联合优化的复杂性，我们首先通过单智能体APO来热身初始<code>predictor</code>，$a_{0}^{*} \leftarrow O_{\mathcal{D}}(a_{0})$，其中指令和示例都与模块化提示词优化器O共同优化。接着在预热过<code>predictor</code>后的条件下，继续以最少数量的智能体优化每个拓扑，$a_{i}^{*} \leftarrow O_{\mathcal{D}}(a_{i} \mid a_{0}^{*})$，这样，2个<code>predictor</code>与1个<code>debator</code>配对形成最小构建块作为<code>debate</code>拓扑，从而降低优化的复杂性，并且该拓扑可以在以后通过更多的<code>predictor</code>和<code>debator</code>进行扩展，但都配备了优化的提示。为了衡量每个构建块的影响，我们在优化完成后存储验证性能。重要的是，尽管阶段（1）作为每个构建块的热身阶段，但它仍然是一个关键阶段，确保后续的拓扑优化在一个有效的空间中进行，组合表现良好的代理，而不是因任何手动提示的格式不佳的代理的复合影响而受苦。</p><p>2）Workflow topology optimization：在此阶段，专注于优化整体MAS结构，确定智能体之间最有效的排列和连接。之前的分析显示，有利的拓扑仅占整个设计空间的一小部分。因此，重点旨在将表现强劲的拓扑的精髓提炼到一个精简的空间，从而使工作流级别的拓扑搜索更加高效。在此，提出测量增量影响$I_{a_{i}} = \frac{\mathcal{E}(a_{i}^{*})}{\mathcal{E}(a_{0}^{*})}$，量化将拓扑$a_{i}$整合到初始代理$a_{0}$中的相对增益。根据直觉，影响力大的维度具有更高的选择概率，如果$u > p_{a}$，则激活相应的拓扑维度a，其中$u ∼ U(0, 1)$且$p_{a} = Softmax(I_{a}, t)$。为了将多样的拓扑组合成一个统一的空间，我们通过基于规则的顺序约束工作流以减少优化复杂性，遵循预定义的顺序，如[<code>summarize</code>，<code>reflect</code>，<code>debate</code>，<code>aggregate</code>]。在预定义的设计空间上整合拒绝采样，拒绝任何停用的维度或超过代理数量最大预算B的无效拓扑组合。</p><p>3）Workflow-level prompt optimization：作为最后一步，我们将整个MAS设计视为一个整体实体，并在第二阶段发现的最佳拓扑$\mathcal{W}^{*} = \mathcal{O}_{\mathcal{D}}(\mathcal{W}_{c}^{*})$的条件下进行额外一轮的提示优化。值得注意的是，尽管在第一阶段提示是在个体层面进行优化的，这一阶段起到了适应或微调的作用，确保提示适合在MAS中进行编排，并且优化了代理之间的相互依赖性。实验表明，这一阶段通常会带来实际的好处。</p><h2 id=试验experiments>试验（Experiments）<a hidden class=anchor aria-hidden=true href=#试验experiments>#</a></h2><h3 id=基准benchmarks>基准（Benchmarks）<a hidden class=anchor aria-hidden=true href=#基准benchmarks>#</a></h3><ol><li>推理：Hendryck&rsquo;s MATH、DROP</li><li>多跳长文本：HotpotQA、MuSiQue、2WikiMultiHopQA</li><li>编程：MBBPP、HumanEval、LCB(LiveCodeBench)</li></ol><h3 id=基线baselines>基线（Baselines）<a hidden class=anchor aria-hidden=true href=#基线baselines>#</a></h3><ol><li>CoT：通过零样本提示进行直接思维链推理。</li><li>CoT-SC：具有自一致性，从多样化的推理轨迹中找到最一致的答案。</li><li>Self-Refine：反思性智能体验证和自我改进预测。</li><li>Multi-Agent Debate：智能体通过辩论答案并聚合其他智能体的信息。</li><li>ADAS：一种自动智能体设计框架，基于LLM的元智能体根据先前的评估迭代提出新智能体</li><li>AFlow：通过蒙特卡罗树搜索在一组预定义的操作符上进行自动工作流设计。</li></ol><p>作者通过将代理的最大数量限制为10来公平比较所有基线。</p><h3 id=实验设置setup>实验设置（Setup）<a hidden class=anchor aria-hidden=true href=#实验设置setup>#</a></h3><p>MASS整合了最先进的提示词优化器MIPRO，通过<code>贝叶斯替代模型（Bayesian surrogate model）</code>优化每个指令和示例。作者限制示例数量为3，候选指令数量为10，每个智能体迭代优化10次。在所有任务的拓扑优化中，作者通过<code>拒绝采样（Rejection sampling）</code>算法搜索10中不同的拓扑结构。与拓扑优化同时，每个拓扑在验证集上评估3次以稳定预测。优化后的MAS随后在保留的测试集上进行了三次运行并报告结果。对于模型，Temperature = 0.7, 最大输出token为4096，Softmax中的t设置为0.05以增强每个搜索维度的选择概率$p_{a}$。在所有阶段，作者都在评估器和优化器中实现了相同的LLM骨干模型。</p><h3 id=主要结果main-results>主要结果（Main Results）<a hidden class=anchor aria-hidden=true href=#主要结果main-results>#</a></h3><p><img alt="Main Results" loading=lazy src=/images/20250626190515.png></p><p>如结果所示，MASS在多智能体系统中取得了显著的提升。通过将MASS与最先进的自动智能体设计基线ADAS和AFlow进行比较，作者注意到，即使ADAS已经基于常见的智能体形式来生成元智能体，它也仅带来了细微的提升。元智能体不断提出复杂的拓扑结构，但没有优化提示词设计。另一方面，AFlow在2WikiMQA和HumanEval上表现出与Mass相当的竞争力。</p><p>作者将AFlow的性能归因于：1）其“扩展”阶段基于错误日志生成新节点，该日志将预测与真实情况进行对比，从而提供隐式文本梯度，以反映提示设计中的任何格式错误；2）在预定义的操作符集合中进行更精细的搜索空间。尽管AFlow在搜索空间设计的重要性上与MASS有相似的灵感，但它仍然缺乏提示词优化阶段来正确优化其预定义的操作符，导致在MATH和MuSiQue的MAS搜索结果中表现不佳。与这些基线不同，Mass带来的持续改进突显了在提示和拓扑设计空间中进行搜索的重要性。</p><h3 id=消融优化阶段ablating-optimization-stages>消融优化阶段（Ablating optimization stages）<a hidden class=anchor aria-hidden=true href=#消融优化阶段ablating-optimization-stages>#</a></h3><p><img alt="Ablating optimization stages" loading=lazy src=/images/20250626190547.png></p><p>首先，注意到块级优化和单智能体优化之间有很大的增益，平均为6%，这表明MAS通过在构建块内优化其智能体受益匪浅。此外，从阶段(1)到(2)，通过在搜索最佳配置时组合有影响力的拓扑结构，可以实现额外的3%增益。在此，作者提供了一个额外的消融研究，探讨在没有事先进行提示优化或没有搜索空间修剪的情况下进行阶段(2)。图（右）显示，这两者对于有效的搜索空间探索都是至关重要的。最后，MASS通过在最佳找到的拓扑上进行工作流级提示优化获得了进一步的增益（约2%），这表明优化提示以建模智能体之间的相互依赖性在MAS设计中是有益的。</p><h3 id=mass的成本效益cost-effectiveness-of-mass>MASS的成本效益（Cost-effectiveness of MASS）<a hidden class=anchor aria-hidden=true href=#mass的成本效益cost-effectiveness-of-mass>#</a></h3><p><img alt="Cost-effectiveness of MASS" loading=lazy src=/images/20250626190620.png></p><p>作者对MASS的成本效益进行了分析。特别是，作者可视化了MASS的优化轨迹，如图所示。MASS的轨迹显示出一种稳定的优化趋势，通过交替搜索更好的提示词和拓扑结构，逐步提高验证性能。然而，对于没有明确提示词优化阶段的自动设计基线，由于MCTS的性质，AFlow在其优化中暴露出更大的方差，而ADAS则陷入发现过于复杂的拓扑结构，这些结构似乎不如提示词计设空间有效。总体而言，MASS的优化轨迹突出了在有效设计空间中进行优化的重要性，其中交替优化通过更多连续的奖励进一步解决了复杂性。</p><h3 id=最佳mas架构与原则best-found-mas-architectures--design-principles>最佳MAS架构与原则（Best-found MAS architectures & Design principles）<a hidden class=anchor aria-hidden=true href=#最佳mas架构与原则best-found-mas-architectures--design-principles>#</a></h3><p><img alt="Best-found MAS architectures & Design principles" loading=lazy src=/images/20250626190659.png></p><p>作者进一步检查了一个优化提示词的示例以及MASS在发现更有效拓扑结构中的轨迹，如图所示。优化从zero-shot CoT智能体开始，很快MASS在阶段(1)中通过其优化提示词识别出高性能拓扑。然而，如阶段(2)中所发现的，聚合更多并行智能体实际上比多智能体辩论更有优势。工作流级别的提示词优化随后导致了聚合的最佳预测器。整体优化流程为我们构建有效MAS的指南提供了启示：1）在将个体智能体组合成MAS之前，适当优化个体智能体是重要的；2）通过组合有影响力的拓扑可以构建更有效的MAS；3）建模智能体之间的相互依赖是有益的，可以通过工作流级别的联合优化实现。</p><h2 id=我的思考-personal-thoughts>我的思考 (Personal Thoughts)<a hidden class=anchor aria-hidden=true href=#我的思考-personal-thoughts>#</a></h2><p>本文对于智能体的优化，着重关注提示词的优化，这一下就抓到了LLM的核心。而对于工作流编排部分，着重需要优化的是工作流的拓扑结构。这给后续多智能体的开发提供了指导，可以增加一些对于智能体提示词和工作流拓扑结构的优化模块。</p><h2 id=参考文献-references>参考文献 (References)<a hidden class=anchor aria-hidden=true href=#参考文献-references>#</a></h2><h3 id=forms-of-llm-based-agentic-systems>Forms of LLM-based agentic systems<a hidden class=anchor aria-hidden=true href=#forms-of-llm-based-agentic-systems>#</a></h3><ul><li>S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. R. Narasimhan, and Y. Cao. React: Synergizing reasoning and acting in language models. In The Eleventh International Conference on Learning Representations, 2023. URL <a href="https://openreview.net/forum?id=WE_vluYUL-X">https://openreview.net/forum?id=WE_vluYUL-X</a>.</li><li>Q. Wu, G. Bansal, J. Zhang, Y. Wu, S. Zhang, E. Zhu, B. Li, L. Jiang, X. Zhang, and C. Wang. Autogen: Enabling next-gen llm applications via multi-agent conversation framework. arXiv preprint arXiv:2308.08155, 2023.</li><li>W. Chen, Y. Su, J. Zuo, C. Yang, C. Yuan, C.-M. Chan, H. Yu, Y. Lu, Y.-H. Hung, C. Qian, Y. Qin, X. Cong, R. Xie, Z. Liu, M. Sun, and J. Zhou. Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors. In The Twelfth International Conference on Learning Representations, 2024b. URL <a href="https://openreview.net/forum?id=EHg5GDnyq1">https://openreview.net/forum?id=EHg5GDnyq1</a>.</li><li>J. Li, Q. Zhang, Y. Yu, Q. FU, and D. Ye. More agents is all you need. Transactions on Machine Learning Research, 2024a. ISSN 2835-8856. URL <a href="https://openreview.net/forum?id=bgzUSZ8aeg">https://openreview.net/forum?id=bgzUSZ8aeg</a>.</li><li>X. Wang, J. Wei, D. Schuurmans, Q. V. Le, E. H. Chi, S. Narang, A. Chowdhery, and D. Zhou. Selfconsistency improves chain of thought reasoning in language models. In The Eleventh International Conference on Learning Representations, 2023. URL <a href="https://openreview.net/forum?id=">https://openreview.net/forum?id=</a> 1PL1NIMMrw.</li><li>A. Madaan, N. Tandon, P. Gupta, S. Hallinan, L. Gao, S. Wiegreffe, U. Alon, N. Dziri, S. Prabhumoye, Y. Yang, et al. Self-refine: Iterative refinement with self-feedback. Advances in Neural Information Processing Systems, 36, 2024.</li><li>A. Singh, A. Ehtesham, S. Kumar, and T. T. Khoei. Agentic retrieval-augmented generation: A survey on agentic rag. arXiv preprint arXiv:2501.09136, 2025.</li><li>X. Chen, M. Lin, N. Schärli, and D. Zhou. Teaching large language models to self-debug. In The Twelfth International Conference on Learning Representations, 2024d. URL https://openreview. net/forum?id=KuPixIqPiq.</li><li>L. Lin, J. Fu, P. Liu, Q. Li, Y. Gong, J. Wan, F. Zhang, Z. Wang, D. Zhang, and K. Gai. Just ask one more time! self-agreement improves reasoning of language models in (almost) all scenarios. In L.-W. Ku, A. Martins, and V. Srikumar, editors, Findings of the Association for Computational Linguistics: ACL 2024, pages 3829–3852, Bangkok, Thailand, Aug. 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.230. URL <a href=https://aclanthology.org/2024>https://aclanthology.org/2024</a>. findings-acl.230/.</li><li>J. Chen, S. Saha, and M. Bansal. ReConcile: Round-table conference improves reasoning via consensus among diverse LLMs. In L.-W. Ku, A. Martins, and V. Srikumar, editors, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 7066–7085, Bangkok, Thailand, Aug. 2024a. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.381. URL <a href=https://aclanthology.org/2024.acl-long.381/>https://aclanthology.org/2024.acl-long.381/</a>.</li><li>Q. Wang, Z. Wang, Y. Su, H. Tong, and Y. Song. Rethinking the bounds of LLM reasoning: Are multi-agent discussions the key? In L.-W. Ku, A. Martins, and V. Srikumar, editors, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6106–6131, Bangkok, Thailand, Aug. 2024c. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.331. URL <a href=https://aclanthology.org/2024.acl-long.331/>https://aclanthology.org/2024.acl-long.331/</a>.</li><li>J. Zhang, X. Xu, N. Zhang, R. Liu, B. Hooi, and S. Deng. Exploring collaboration mechanisms for LLM agents: A social psychology view. In L.-W. Ku, A. Martins, and V. Srikumar, editors, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14544–14607, Bangkok, Thailand, Aug. 2024c. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.782. URL <a href=https://aclanthology.org/2024.acl-long.782/>https://aclanthology.org/2024.acl-long.782/</a>.</li><li>Y. Du, S. Li, A. Torralba, J. B. Tenenbaum, and I. Mordatch. Improving factuality and reasoning in language models through multiagent debate. In Forty-first International Conference on Machine Learning, ICML 2024, Vienna, Austria, July 21-27, 2024. OpenReview.net, 2024. URL https: //openreview.net/forum?id=zj7YuTE4t8.</li><li>A. Khan, J. Hughes, D. Valentine, L. Ruis, K. Sachan, A. Radhakrishnan, E. Grefenstette, S. R. Bowman, T. Rocktäschel, and E. Perez. Debating with more persuasive LLMs leads to more truthful answers. In Forty-first International Conference on Machine Learning, 2024. URL https://openreview. net/forum?id=iLCZtl7FTa.</li><li>C. Qian, Z. Xie, Y. Wang, W. Liu, Y. Dang, Z. Du, W. Chen, C. Yang, Z. Liu, and M. Sun. Scaling large-language-model-based multi-agent collaboration. arXiv preprint arXiv:2406.07155, 2024.</li><li>J. Wang, J. Wang, B. Athiwaratkun, C. Zhang, and J. Zou. Mixture-of-agents enhances large language model capabilities. arXiv preprint arXiv:2406.04692, 2024b.</li></ul><h3 id=automatic-optimization-for-mas>Automatic optimization for MAS<a hidden class=anchor aria-hidden=true href=#automatic-optimization-for-mas>#</a></h3><ul><li>S. Zhang, J. Zhang, J. Liu, L. Song, C. Wang, R. Krishna, and Q. Wu. Offline training of language model agents with functions as learnable weights. In Forty-first International Conference on Machine Learning, 2024d. URL <a href="https://openreview.net/forum?id=2xbkWiEuR1">https://openreview.net/forum?id=2xbkWiEuR1</a>.</li><li>W. Zhang, K. Tang, H. Wu, M. Wang, Y. Shen, G. Hou, Z. Tan, P. Li, Y. Zhuang, and W. Lu. Agentpro: Learning to evolve via policy-level reflection and optimization. In L.-W. Ku, A. Martins, and V. Srikumar, editors, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5348–5375, Bangkok, Thailand, Aug. 2024e. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.292. URL <a href=https://aclanthology.org/2024.acl-long.292/>https://aclanthology.org/2024.acl-long.292/</a>.</li><li>S. Qiao, N. Zhang, R. Fang, Y. Luo, W. Zhou, Y. Jiang, C. Lv, and H. Chen. AutoAct: Automatic agent learning from scratch for QA via self-planning. In L.-W. Ku, A. Martins, and V. Srikumar, editors, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3003–3021, Bangkok, Thailand, Aug. 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.165. URL <a href=https://aclanthology.org/2024>https://aclanthology.org/2024</a>. acl-long.165/.</li><li>O. Khattab, A. Singhvi, P. Maheshwari, Z. Zhang, K. Santhanam, S. V. A, S. Haq, A. Sharma, T. T. Joshi, H. Moazam, H. Miller, M. Zaharia, and C. Potts. DSPy: Compiling declarative language model calls into state-of-the-art pipelines. In The Twelfth International Conference on Learning Representations, 2024. URL <a href="https://openreview.net/forum?id=sY5N0zY5Od">https://openreview.net/forum?id=sY5N0zY5Od</a>.</li><li>W. Zhou, Y. Ou, S. Ding, L. Li, J. Wu, T. Wang, J. Chen, S. Wang, X. Xu, N. Zhang, et al. Symbolic learning enables self-evolving agents. arXiv preprint arXiv:2406.18532, 2024d.</li><li>Z. Li, S. Xu, K. Mei, W. Hua, B. Rama, O. Raheja, H. Wang, H. Zhu, and Y. Zhang. Autoflow: Automated workflow generation for large language model agents. arXiv preprint arXiv:2407.12821, 2024c.</li><li>Y. Shang, Y. Li, K. Zhao, L. Ma, J. Liu, F. Xu, and Y. Li. Agentsquare: Automatic llm agent search in modular design space. arXiv preprint arXiv:2410.06153, 2024.</li><li>Z. Liu, Y. Zhang, P. Li, Y. Liu, and D. Yang. A dynamic LLM-powered agent network for taskoriented agent collaboration. In First Conference on Language Modeling, 2024b. URL https: //openreview.net/forum?id=XII0Wp1XA9.</li><li>J. Saad-Falcon, A. G. Lafuente, S. Natarajan, N. Maru, H. Todorov, E. Guha, E. K. Buchanan, M. Chen, N. Guha, C. Ré, et al. Archon: An architecture search framework for inference-time techniques. arXiv preprint arXiv:2409.15254, 2024.</li><li>M. Zhuge, W. Wang, L. Kirsch, F. Faccio, D. Khizbullin, and J. Schmidhuber. GPTSwarm: Language agents as optimizable graphs. In Forty-first International Conference on Machine Learning, 2024. URL <a href="https://openreview.net/forum?id=uTC9AFXIhg">https://openreview.net/forum?id=uTC9AFXIhg</a>.</li><li>S. Hu, C. Lu, and J. Clune. Automated design of agentic systems. arXiv preprint arXiv:2408.08435, 2024a.</li><li>J. Zhang, J. Xiang, Z. Yu, F. Teng, X. Chen, J. Chen, M. Zhuge, X. Cheng, S. Hong, J. Wang, et al. Aflow: Automating agentic workflow generation. arXiv preprint arXiv:2410.10762, 2024b.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=http://rextechie.github.io/tags/mas/>MAS</a></li><li><a href=http://rextechie.github.io/tags/agent/>Agent</a></li></ul><nav class=paginav><a class=prev href=http://rextechie.github.io/posts/design_patterns/overview/><span class=title>« Prev</span><br><span>设计模式笔记索引</span>
</a><a class=next href=http://rextechie.github.io/posts/java/springcloudalibaba/><span class=title>Next »</span><br><span>Spring Cloud Alibaba 中间件</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies on x" href="https://x.com/intent/tweet/?text=Multi-Agent%20Design%3a%20Optimizing%20Agents%20with%20Better%20Prompts%20and%20Topologies&amp;url=http%3a%2f%2frextechie.github.io%2fposts%2fpaper_note%2fmulti_agent_design%2f&amp;hashtags=MAS%2cAgent"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2frextechie.github.io%2fposts%2fpaper_note%2fmulti_agent_design%2f&amp;title=Multi-Agent%20Design%3a%20Optimizing%20Agents%20with%20Better%20Prompts%20and%20Topologies&amp;summary=Multi-Agent%20Design%3a%20Optimizing%20Agents%20with%20Better%20Prompts%20and%20Topologies&amp;source=http%3a%2f%2frextechie.github.io%2fposts%2fpaper_note%2fmulti_agent_design%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies on reddit" href="https://reddit.com/submit?url=http%3a%2f%2frextechie.github.io%2fposts%2fpaper_note%2fmulti_agent_design%2f&title=Multi-Agent%20Design%3a%20Optimizing%20Agents%20with%20Better%20Prompts%20and%20Topologies"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2frextechie.github.io%2fposts%2fpaper_note%2fmulti_agent_design%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies on whatsapp" href="https://api.whatsapp.com/send?text=Multi-Agent%20Design%3a%20Optimizing%20Agents%20with%20Better%20Prompts%20and%20Topologies%20-%20http%3a%2f%2frextechie.github.io%2fposts%2fpaper_note%2fmulti_agent_design%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies on telegram" href="https://telegram.me/share/url?text=Multi-Agent%20Design%3a%20Optimizing%20Agents%20with%20Better%20Prompts%20and%20Topologies&amp;url=http%3a%2f%2frextechie.github.io%2fposts%2fpaper_note%2fmulti_agent_design%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies on ycombinator" href="https://news.ycombinator.com/submitlink?t=Multi-Agent%20Design%3a%20Optimizing%20Agents%20with%20Better%20Prompts%20and%20Topologies&u=http%3a%2f%2frextechie.github.io%2fposts%2fpaper_note%2fmulti_agent_design%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer><script src=https://utteranc.es/client.js repo=RexTechie/blogcomment issue-term=pathname theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=http://rextechie.github.io/>RexBlog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>